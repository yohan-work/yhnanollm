"""
ë²¡í„° ìŠ¤í† ì–´ ëª¨ë“ˆ
ChromaDBë¥¼ ì‚¬ìš©í•œ ë¬¸ì„œ ì„ë² ë”© ë° ê²€ìƒ‰
"""

import chromadb
from sentence_transformers import SentenceTransformer
from typing import List, Dict, Optional
import hashlib


class VectorStore:
    def __init__(self, persist_directory: str = "chroma_db"):
        """
        ë²¡í„° ìŠ¤í† ì–´ ì´ˆê¸°í™”
        
        Args:
            persist_directory: ChromaDB ì €ì¥ ê²½ë¡œ
        """
        self.persist_directory = persist_directory
        
        # ChromaDB í´ë¼ì´ì–¸íŠ¸ ìƒì„±
        self.client = chromadb.PersistentClient(path=persist_directory)
        
        # ì»¬ë ‰ì…˜ ìƒì„± ë˜ëŠ” ê°€ì ¸ì˜¤ê¸°
        self.collection = self.client.get_or_create_collection(
            name="documents",
            metadata={"description": "yhnanollm document embeddings"}
        )
        
        # ì„ë² ë”© ëª¨ë¸ ë¡œë“œ (í•œêµ­ì–´ ì§€ì›)
        print("ğŸ”„ ì„ë² ë”© ëª¨ë¸ ë¡œë”© ì¤‘...")
        self.embedder = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')
        print("âœ… ì„ë² ë”© ëª¨ë¸ ì¤€ë¹„ ì™„ë£Œ")
    
    def add_documents(self, chunks: List[Dict[str, str]]) -> None:
        """
        ë¬¸ì„œ ì²­í¬ë¥¼ ë²¡í„° DBì— ì¶”ê°€
        
        Args:
            chunks: ë¬¸ì„œ ì²­í¬ ë¦¬ìŠ¤íŠ¸
        """
        if not chunks:
            return
        
        print(f"{len(chunks)}ê°œ ì²­í¬ ì„ë² ë”© ì¤‘...")
        
        texts = [chunk['text'] for chunk in chunks]
        metadatas = [chunk['metadata'] for chunk in chunks]
        
        # í…ìŠ¤íŠ¸ë¥¼ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜
        embeddings = self.embedder.encode(texts, show_progress_bar=True)
        
        # ê³ ìœ  ID ìƒì„± (íŒŒì¼ëª… + ì²­í¬ ID)
        ids = []
        for meta in metadatas:
            doc_id = f"{meta['filename']}_{meta['chunk_id']}"
            # í•´ì‹œë¡œ ê³ ìœ ì„± ë³´ì¥
            doc_hash = hashlib.md5(doc_id.encode()).hexdigest()[:8]
            ids.append(f"{doc_hash}_{meta['chunk_id']}")
        
        # ChromaDBì— ì¶”ê°€
        self.collection.add(
            embeddings=embeddings.tolist(),
            documents=texts,
            metadatas=metadatas,
            ids=ids
        )
        
        print(f"{len(chunks)}ê°œ ì²­í¬ ì €ì¥ ì™„ë£Œ")
    
    def search(self, query: str, top_k: int = 3) -> Dict:
        """
        ì§ˆë¬¸ê³¼ ìœ ì‚¬í•œ ë¬¸ì„œ ê²€ìƒ‰
        
        Args:
            query: ê²€ìƒ‰ ì§ˆë¬¸
            top_k: ë°˜í™˜í•  ë¬¸ì„œ ìˆ˜
            
        Returns:
            ê²€ìƒ‰ ê²°ê³¼ (documents, metadatas, distances)
        """
        # ì§ˆë¬¸ì„ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜
        query_embedding = self.embedder.encode([query])
        
        # ìœ ì‚¬ë„ ê²€ìƒ‰
        results = self.collection.query(
            query_embeddings=query_embedding.tolist(),
            n_results=min(top_k, self.collection.count())
        )
        
        return results
    
    def get_document_count(self) -> int:
        """
        ì €ì¥ëœ ë¬¸ì„œ ì²­í¬ ìˆ˜ ë°˜í™˜
        """
        return self.collection.count()
    
    def clear(self) -> None:
        """
        ëª¨ë“  ë¬¸ì„œ ì‚­ì œ
        """
        # ì»¬ë ‰ì…˜ ì‚­ì œ í›„ ì¬ìƒì„±
        self.client.delete_collection("documents")
        self.collection = self.client.get_or_create_collection(
            name="documents",
            metadata={"description": "yhnanollm document embeddings"}
        )
        print("ë²¡í„° DB ì´ˆê¸°í™” ì™„ë£Œ")

