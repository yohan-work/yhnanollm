#!/usr/bin/env python3
"""
MLX LoRA Merge & Test Script for yhnanollm v1.0.0-beta
LoRA ì–´ëŒ‘í„°ë¥¼ ë² ì´ìŠ¤ ëª¨ë¸ê³¼ ë³‘í•©í•˜ê³  í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.
"""

import argparse
from pathlib import Path
from mlx_lm import load, generate


def test_model(model, tokenizer, prompt):
    """ëª¨ë¸ í…ŒìŠ¤íŠ¸ ë° ìƒì„±"""
    print(f"\nğŸ’¬ í”„ë¡¬í”„íŠ¸: {prompt}")
    print("ğŸ¤– ì‘ë‹µ: ", end="", flush=True)
    
    # ì‘ë‹µ ìƒì„± (MLX-LM ìµœì‹  API ì‚¬ìš©)
    response = generate(
        model,
        tokenizer,
        prompt=prompt,
        max_tokens=100,
        verbose=False
    )
    
    print(response)
    return response


def main():
    parser = argparse.ArgumentParser(description="MLX LoRA Merge & Test")
    parser.add_argument("--model", type=str, default="mlx-community/Llama-3.2-1B-Instruct-4bit",
                        help="Base model path or HF repo (í† í° ë¶ˆí•„ìš”í•œ ê³µê°œ ëª¨ë¸)")
    parser.add_argument("--adapter", type=str, default="models/lora-adapter",
                        help="LoRA adapter path")
    parser.add_argument("--output", type=str, default="models/merged-model",
                        help="Output directory for merged model")
    parser.add_argument("--test-only", action="store_true",
                        help="Skip merging and only test")
    parser.add_argument("--prompt", type=str, default="ì•ˆë…•í•˜ì„¸ìš”?",
                        help="Test prompt")
    
    args = parser.parse_args()
    
    print(f"ğŸ”§ yhnanollm v1.0.0-beta LoRA Merge & Test")
    print(f"ğŸ“¦ ë² ì´ìŠ¤ ëª¨ë¸: {args.model}")
    print(f"ğŸ¯ LoRA ì–´ëŒ‘í„°: {args.adapter}")
    
    # LoRA ì–´ëŒ‘í„°ê°€ ìˆëŠ”ì§€ í™•ì¸
    adapter_path = Path(args.adapter)
    if not adapter_path.exists() or not any(adapter_path.glob("*.safetensors")):
        print("\nâš ï¸  ê²½ê³ : LoRA ì–´ëŒ‘í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print(f"   {args.adapter} ê²½ë¡œì— í•™ìŠµëœ ì–´ëŒ‘í„°ê°€ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
        print("   ë¨¼ì € scripts/finetune.pyë¥¼ ì‹¤í–‰í•˜ì—¬ í•™ìŠµì„ ì§„í–‰í•˜ì„¸ìš”.")
        return
    
    if not args.test_only:
        # ëª¨ë¸ ë³‘í•©
        print(f"\nğŸ”„ LoRA ì–´ëŒ‘í„° ë³‘í•© ì¤‘...")
        print(f"ğŸ’¾ ì¶œë ¥ ê²½ë¡œ: {args.output}")
        
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        Path(args.output).mkdir(parents=True, exist_ok=True)
        
        # MLX-LMì„ ì‚¬ìš©í•œ ë³‘í•©
        print("\nğŸ’¡ MLX-LM CLIë¥¼ ì‚¬ìš©í•˜ì—¬ ë³‘í•©:")
        print(f"   mlx_lm.fuse \\")
        print(f"     --model {args.model} \\")
        print(f"     --adapter-path {args.adapter} \\")
        print(f"     --save-path {args.output}")
        
        print("\n" + "="*60)
        print("âš ï¸  ì‹¤ì œ ë³‘í•©ì„ ìœ„í•´ ìœ„ ëª…ë ¹ì–´ë¥¼ í„°ë¯¸ë„ì—ì„œ ì‹¤í–‰í•˜ì„¸ìš”.")
        print("="*60)
    
    # ëª¨ë¸ í…ŒìŠ¤íŠ¸
    print(f"\nğŸ§ª ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì‹œì‘...")
    
    try:
        # LoRA ì–´ëŒ‘í„°ì™€ í•¨ê»˜ ëª¨ë¸ ë¡œë“œ
        print(f"ğŸ“¥ ëª¨ë¸ ë¡œë”© ì¤‘... (LoRA í¬í•¨)")
        model, tokenizer = load(
            args.model,
            adapter_path=args.adapter
        )
        print("âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ")
        
        # í…ŒìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ë“¤
        test_prompts = [
            args.prompt,
            "MLXê°€ ë­ì•¼?",
            "íŒŒì´ì¬ì´ë€?"
        ]
        
        print("\n" + "="*60)
        print("í…ŒìŠ¤íŠ¸ ê²°ê³¼:")
        print("="*60)
        
        for prompt in test_prompts:
            test_model(model, tokenizer, prompt)
            print("-"*60)
        
        print("\nâœ¨ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        print("   ëª¨ë¸ê³¼ ì–´ëŒ‘í„° ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”.")


if __name__ == "__main__":
    main()

